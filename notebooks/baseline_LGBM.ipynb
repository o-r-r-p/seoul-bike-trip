{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "528b2cd2-917c-47d8-8ef9-b11ddb1925b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "\n",
    "import lightgbm as lgb\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# スクリプトのあるディレクトリの絶対パスを取得\n",
    "script_dir = str(Path('../scripts').resolve())\n",
    "\n",
    "# sys.pathにスクリプトのディレクトリを追加\n",
    "if script_dir not in sys.path:\n",
    "    sys.path.insert(0, script_dir)\n",
    "\n",
    "from preprocess import reduce_mem_usage, feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7e033f-272b-45aa-9409-504d10f92d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reduce_mem_usage(pl.scan_parquet(\"../data/train.parquet\")).collect().to_pandas()\n",
    "test = reduce_mem_usage(pl.scan_parquet(\"../data/test.parquet\")).collect().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23a8f97c-67aa-4384-abe2-2da7399f6f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold: 1 Start\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 15.8819\tvalid_1's rmse: 15.8756\n",
      "[200]\ttraining's rmse: 13.8653\tvalid_1's rmse: 13.8658\n",
      "[300]\ttraining's rmse: 12.9781\tvalid_1's rmse: 12.9811\n",
      "[400]\ttraining's rmse: 11.9554\tvalid_1's rmse: 11.96\n",
      "[500]\ttraining's rmse: 10.9836\tvalid_1's rmse: 10.9924\n",
      "[600]\ttraining's rmse: 10.2798\tvalid_1's rmse: 10.2932\n",
      "[700]\ttraining's rmse: 9.77334\tvalid_1's rmse: 9.78912\n",
      "[800]\ttraining's rmse: 9.3604\tvalid_1's rmse: 9.37803\n",
      "[900]\ttraining's rmse: 8.98296\tvalid_1's rmse: 9.00301\n",
      "[1000]\ttraining's rmse: 8.62854\tvalid_1's rmse: 8.65046\n",
      "[1100]\ttraining's rmse: 8.31561\tvalid_1's rmse: 8.33955\n",
      "[1200]\ttraining's rmse: 8.03607\tvalid_1's rmse: 8.06162\n",
      "[1300]\ttraining's rmse: 7.79363\tvalid_1's rmse: 7.82111\n",
      "[1400]\ttraining's rmse: 7.58443\tvalid_1's rmse: 7.61395\n",
      "[1500]\ttraining's rmse: 7.37304\tvalid_1's rmse: 7.40455\n",
      "[1600]\ttraining's rmse: 7.18117\tvalid_1's rmse: 7.21403\n",
      "[1700]\ttraining's rmse: 6.98822\tvalid_1's rmse: 7.02248\n",
      "[1800]\ttraining's rmse: 6.81054\tvalid_1's rmse: 6.84644\n",
      "[1900]\ttraining's rmse: 6.64786\tvalid_1's rmse: 6.68469\n",
      "[2000]\ttraining's rmse: 6.4995\tvalid_1's rmse: 6.53764\n",
      "[2100]\ttraining's rmse: 6.36908\tvalid_1's rmse: 6.4083\n",
      "[2200]\ttraining's rmse: 6.24002\tvalid_1's rmse: 6.28048\n",
      "[2300]\ttraining's rmse: 6.11738\tvalid_1's rmse: 6.15875\n",
      "[2400]\ttraining's rmse: 5.99843\tvalid_1's rmse: 6.04142\n",
      "[2500]\ttraining's rmse: 5.88827\tvalid_1's rmse: 5.93274\n",
      "[2600]\ttraining's rmse: 5.77495\tvalid_1's rmse: 5.82064\n",
      "[2700]\ttraining's rmse: 5.66415\tvalid_1's rmse: 5.71136\n",
      "[2800]\ttraining's rmse: 5.56162\tvalid_1's rmse: 5.61\n",
      "[2900]\ttraining's rmse: 5.45442\tvalid_1's rmse: 5.50437\n",
      "[3000]\ttraining's rmse: 5.35354\tvalid_1's rmse: 5.4046\n",
      "[3100]\ttraining's rmse: 5.26201\tvalid_1's rmse: 5.3148\n",
      "[3200]\ttraining's rmse: 5.16392\tvalid_1's rmse: 5.21832\n",
      "[3300]\ttraining's rmse: 5.08149\tvalid_1's rmse: 5.13737\n",
      "[3400]\ttraining's rmse: 4.99552\tvalid_1's rmse: 5.05293\n",
      "[3500]\ttraining's rmse: 4.90568\tvalid_1's rmse: 4.96507\n",
      "[3600]\ttraining's rmse: 4.83552\tvalid_1's rmse: 4.89623\n",
      "[3700]\ttraining's rmse: 4.77029\tvalid_1's rmse: 4.83263\n",
      "[3800]\ttraining's rmse: 4.71156\tvalid_1's rmse: 4.77478\n",
      "[3900]\ttraining's rmse: 4.64971\tvalid_1's rmse: 4.7142\n",
      "[4000]\ttraining's rmse: 4.59037\tvalid_1's rmse: 4.65562\n",
      "[4100]\ttraining's rmse: 4.52507\tvalid_1's rmse: 4.59124\n",
      "[4200]\ttraining's rmse: 4.46833\tvalid_1's rmse: 4.53547\n",
      "[4300]\ttraining's rmse: 4.4129\tvalid_1's rmse: 4.48099\n",
      "[4400]\ttraining's rmse: 4.36281\tvalid_1's rmse: 4.432\n",
      "[4500]\ttraining's rmse: 4.30899\tvalid_1's rmse: 4.379\n",
      "[4600]\ttraining's rmse: 4.2562\tvalid_1's rmse: 4.32724\n",
      "[4700]\ttraining's rmse: 4.20194\tvalid_1's rmse: 4.27413\n",
      "[4800]\ttraining's rmse: 4.1547\tvalid_1's rmse: 4.228\n",
      "[4900]\ttraining's rmse: 4.10544\tvalid_1's rmse: 4.17927\n",
      "[5000]\ttraining's rmse: 4.05996\tvalid_1's rmse: 4.13416\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's rmse: 4.05996\tvalid_1's rmse: 4.13416\n",
      "KFold: 1 ==> RMSE: 4.1287\n",
      "KFold: 2 Start\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 15.8851\tvalid_1's rmse: 15.8904\n",
      "[200]\ttraining's rmse: 13.8579\tvalid_1's rmse: 13.8665\n",
      "[300]\ttraining's rmse: 12.9573\tvalid_1's rmse: 12.9671\n",
      "[400]\ttraining's rmse: 11.9259\tvalid_1's rmse: 11.9406\n",
      "[500]\ttraining's rmse: 11.0052\tvalid_1's rmse: 11.0219\n",
      "[600]\ttraining's rmse: 10.3035\tvalid_1's rmse: 10.3206\n",
      "[700]\ttraining's rmse: 9.8077\tvalid_1's rmse: 9.82584\n",
      "[800]\ttraining's rmse: 9.40201\tvalid_1's rmse: 9.42078\n",
      "[900]\ttraining's rmse: 9.02663\tvalid_1's rmse: 9.04527\n",
      "[1000]\ttraining's rmse: 8.68655\tvalid_1's rmse: 8.70463\n",
      "[1100]\ttraining's rmse: 8.40182\tvalid_1's rmse: 8.42\n",
      "[1200]\ttraining's rmse: 8.10632\tvalid_1's rmse: 8.12463\n",
      "[1300]\ttraining's rmse: 7.83462\tvalid_1's rmse: 7.85319\n",
      "[1400]\ttraining's rmse: 7.60619\tvalid_1's rmse: 7.62489\n",
      "[1500]\ttraining's rmse: 7.39199\tvalid_1's rmse: 7.41122\n",
      "[1600]\ttraining's rmse: 7.20993\tvalid_1's rmse: 7.23009\n",
      "[1700]\ttraining's rmse: 7.01119\tvalid_1's rmse: 7.031\n",
      "[1800]\ttraining's rmse: 6.82985\tvalid_1's rmse: 6.8498\n",
      "[1900]\ttraining's rmse: 6.6621\tvalid_1's rmse: 6.6823\n",
      "[2000]\ttraining's rmse: 6.5121\tvalid_1's rmse: 6.53309\n",
      "[2100]\ttraining's rmse: 6.36612\tvalid_1's rmse: 6.38817\n",
      "[2200]\ttraining's rmse: 6.24066\tvalid_1's rmse: 6.26316\n",
      "[2300]\ttraining's rmse: 6.11064\tvalid_1's rmse: 6.13399\n",
      "[2400]\ttraining's rmse: 5.99557\tvalid_1's rmse: 6.01955\n",
      "[2500]\ttraining's rmse: 5.88313\tvalid_1's rmse: 5.90762\n",
      "[2600]\ttraining's rmse: 5.77011\tvalid_1's rmse: 5.79532\n",
      "[2700]\ttraining's rmse: 5.66111\tvalid_1's rmse: 5.68726\n",
      "[2800]\ttraining's rmse: 5.55826\tvalid_1's rmse: 5.58491\n",
      "[2900]\ttraining's rmse: 5.45742\tvalid_1's rmse: 5.48424\n",
      "[3000]\ttraining's rmse: 5.35307\tvalid_1's rmse: 5.38007\n",
      "[3100]\ttraining's rmse: 5.26191\tvalid_1's rmse: 5.28897\n",
      "[3200]\ttraining's rmse: 5.16542\tvalid_1's rmse: 5.19261\n",
      "[3300]\ttraining's rmse: 5.08029\tvalid_1's rmse: 5.10758\n",
      "[3400]\ttraining's rmse: 4.99521\tvalid_1's rmse: 5.02236\n",
      "[3500]\ttraining's rmse: 4.92057\tvalid_1's rmse: 4.94841\n",
      "[3600]\ttraining's rmse: 4.83961\tvalid_1's rmse: 4.86801\n",
      "[3700]\ttraining's rmse: 4.76659\tvalid_1's rmse: 4.79579\n",
      "[3800]\ttraining's rmse: 4.70137\tvalid_1's rmse: 4.73102\n",
      "[3900]\ttraining's rmse: 4.64254\tvalid_1's rmse: 4.67263\n",
      "[4000]\ttraining's rmse: 4.57985\tvalid_1's rmse: 4.61019\n",
      "[4100]\ttraining's rmse: 4.51356\tvalid_1's rmse: 4.54437\n",
      "[4200]\ttraining's rmse: 4.45216\tvalid_1's rmse: 4.48319\n",
      "[4300]\ttraining's rmse: 4.39481\tvalid_1's rmse: 4.42565\n",
      "[4400]\ttraining's rmse: 4.33575\tvalid_1's rmse: 4.36666\n",
      "[4500]\ttraining's rmse: 4.28427\tvalid_1's rmse: 4.31571\n",
      "[4600]\ttraining's rmse: 4.23466\tvalid_1's rmse: 4.26676\n",
      "[4700]\ttraining's rmse: 4.18728\tvalid_1's rmse: 4.2204\n",
      "[4800]\ttraining's rmse: 4.13939\tvalid_1's rmse: 4.1731\n",
      "[4900]\ttraining's rmse: 4.09595\tvalid_1's rmse: 4.13075\n",
      "[5000]\ttraining's rmse: 4.05636\tvalid_1's rmse: 4.0918\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's rmse: 4.05636\tvalid_1's rmse: 4.0918\n",
      "KFold: 2 ==> RMSE: 4.1210\n",
      "KFold: 3 Start\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 15.8908\tvalid_1's rmse: 15.8534\n",
      "[200]\ttraining's rmse: 13.8831\tvalid_1's rmse: 13.8439\n",
      "[300]\ttraining's rmse: 12.9682\tvalid_1's rmse: 12.9284\n",
      "[400]\ttraining's rmse: 11.9406\tvalid_1's rmse: 11.9076\n",
      "[500]\ttraining's rmse: 10.9622\tvalid_1's rmse: 10.9393\n",
      "[600]\ttraining's rmse: 10.2779\tvalid_1's rmse: 10.2605\n",
      "[700]\ttraining's rmse: 9.74584\tvalid_1's rmse: 9.73216\n",
      "[800]\ttraining's rmse: 9.31205\tvalid_1's rmse: 9.30121\n",
      "[900]\ttraining's rmse: 8.94963\tvalid_1's rmse: 8.94162\n",
      "[1000]\ttraining's rmse: 8.60502\tvalid_1's rmse: 8.59965\n",
      "[1100]\ttraining's rmse: 8.28756\tvalid_1's rmse: 8.28519\n",
      "[1200]\ttraining's rmse: 8.00214\tvalid_1's rmse: 8.0015\n",
      "[1300]\ttraining's rmse: 7.76664\tvalid_1's rmse: 7.76766\n",
      "[1400]\ttraining's rmse: 7.53947\tvalid_1's rmse: 7.54266\n",
      "[1500]\ttraining's rmse: 7.33231\tvalid_1's rmse: 7.33771\n",
      "[1600]\ttraining's rmse: 7.13454\tvalid_1's rmse: 7.14208\n",
      "[1700]\ttraining's rmse: 6.95395\tvalid_1's rmse: 6.96367\n",
      "[1800]\ttraining's rmse: 6.78394\tvalid_1's rmse: 6.79537\n",
      "[1900]\ttraining's rmse: 6.61771\tvalid_1's rmse: 6.63109\n",
      "[2000]\ttraining's rmse: 6.45742\tvalid_1's rmse: 6.4729\n",
      "[2100]\ttraining's rmse: 6.30884\tvalid_1's rmse: 6.32588\n",
      "[2200]\ttraining's rmse: 6.17152\tvalid_1's rmse: 6.19059\n",
      "[2300]\ttraining's rmse: 6.0522\tvalid_1's rmse: 6.07271\n",
      "[2400]\ttraining's rmse: 5.93266\tvalid_1's rmse: 5.95546\n",
      "[2500]\ttraining's rmse: 5.81592\tvalid_1's rmse: 5.84072\n",
      "[2600]\ttraining's rmse: 5.7042\tvalid_1's rmse: 5.73052\n",
      "[2700]\ttraining's rmse: 5.60094\tvalid_1's rmse: 5.62904\n",
      "[2800]\ttraining's rmse: 5.49879\tvalid_1's rmse: 5.52798\n",
      "[2900]\ttraining's rmse: 5.39938\tvalid_1's rmse: 5.43033\n",
      "[3000]\ttraining's rmse: 5.30944\tvalid_1's rmse: 5.34186\n",
      "[3100]\ttraining's rmse: 5.2169\tvalid_1's rmse: 5.25056\n",
      "[3200]\ttraining's rmse: 5.12822\tvalid_1's rmse: 5.16351\n",
      "[3300]\ttraining's rmse: 5.041\tvalid_1's rmse: 5.07778\n",
      "[3400]\ttraining's rmse: 4.96227\tvalid_1's rmse: 5.00053\n",
      "[3500]\ttraining's rmse: 4.88789\tvalid_1's rmse: 4.9279\n",
      "[3600]\ttraining's rmse: 4.81385\tvalid_1's rmse: 4.85534\n",
      "[3700]\ttraining's rmse: 4.7519\tvalid_1's rmse: 4.7948\n",
      "[3800]\ttraining's rmse: 4.68018\tvalid_1's rmse: 4.72459\n",
      "[3900]\ttraining's rmse: 4.61352\tvalid_1's rmse: 4.65932\n",
      "[4000]\ttraining's rmse: 4.55156\tvalid_1's rmse: 4.59919\n",
      "[4100]\ttraining's rmse: 4.4928\tvalid_1's rmse: 4.542\n",
      "[4200]\ttraining's rmse: 4.43652\tvalid_1's rmse: 4.48757\n",
      "[4300]\ttraining's rmse: 4.37372\tvalid_1's rmse: 4.42629\n",
      "[4400]\ttraining's rmse: 4.31909\tvalid_1's rmse: 4.37316\n",
      "[4500]\ttraining's rmse: 4.27073\tvalid_1's rmse: 4.32597\n",
      "[4600]\ttraining's rmse: 4.22281\tvalid_1's rmse: 4.27898\n",
      "[4700]\ttraining's rmse: 4.17418\tvalid_1's rmse: 4.23158\n",
      "[4800]\ttraining's rmse: 4.13208\tvalid_1's rmse: 4.19044\n",
      "[4900]\ttraining's rmse: 4.07887\tvalid_1's rmse: 4.13851\n",
      "[5000]\ttraining's rmse: 4.02502\tvalid_1's rmse: 4.08631\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's rmse: 4.02502\tvalid_1's rmse: 4.08631\n",
      "KFold: 3 ==> RMSE: 4.0889\n",
      "KFold: 4 Start\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 15.8797\tvalid_1's rmse: 15.8992\n",
      "[200]\ttraining's rmse: 13.8654\tvalid_1's rmse: 13.8841\n",
      "[300]\ttraining's rmse: 12.9569\tvalid_1's rmse: 12.9762\n",
      "[400]\ttraining's rmse: 11.9378\tvalid_1's rmse: 11.9575\n",
      "[500]\ttraining's rmse: 10.9884\tvalid_1's rmse: 11.0085\n",
      "[600]\ttraining's rmse: 10.2954\tvalid_1's rmse: 10.3165\n",
      "[700]\ttraining's rmse: 9.81166\tvalid_1's rmse: 9.83354\n",
      "[800]\ttraining's rmse: 9.40174\tvalid_1's rmse: 9.4248\n",
      "[900]\ttraining's rmse: 9.00456\tvalid_1's rmse: 9.02829\n",
      "[1000]\ttraining's rmse: 8.62786\tvalid_1's rmse: 8.65198\n",
      "[1100]\ttraining's rmse: 8.31656\tvalid_1's rmse: 8.34115\n",
      "[1200]\ttraining's rmse: 8.05249\tvalid_1's rmse: 8.07799\n",
      "[1300]\ttraining's rmse: 7.82454\tvalid_1's rmse: 7.85131\n",
      "[1400]\ttraining's rmse: 7.61517\tvalid_1's rmse: 7.6435\n",
      "[1500]\ttraining's rmse: 7.41261\tvalid_1's rmse: 7.44197\n",
      "[1600]\ttraining's rmse: 7.22396\tvalid_1's rmse: 7.25346\n",
      "[1700]\ttraining's rmse: 7.03852\tvalid_1's rmse: 7.06868\n",
      "[1800]\ttraining's rmse: 6.86883\tvalid_1's rmse: 6.89928\n",
      "[1900]\ttraining's rmse: 6.69462\tvalid_1's rmse: 6.72562\n",
      "[2000]\ttraining's rmse: 6.53277\tvalid_1's rmse: 6.56488\n",
      "[2100]\ttraining's rmse: 6.38402\tvalid_1's rmse: 6.4165\n",
      "[2200]\ttraining's rmse: 6.24924\tvalid_1's rmse: 6.28178\n",
      "[2300]\ttraining's rmse: 6.11656\tvalid_1's rmse: 6.14991\n",
      "[2400]\ttraining's rmse: 5.98886\tvalid_1's rmse: 6.02291\n",
      "[2500]\ttraining's rmse: 5.86367\tvalid_1's rmse: 5.89845\n",
      "[2600]\ttraining's rmse: 5.73279\tvalid_1's rmse: 5.7689\n",
      "[2700]\ttraining's rmse: 5.62603\tvalid_1's rmse: 5.66326\n",
      "[2800]\ttraining's rmse: 5.51356\tvalid_1's rmse: 5.55186\n",
      "[2900]\ttraining's rmse: 5.40563\tvalid_1's rmse: 5.44562\n",
      "[3000]\ttraining's rmse: 5.30833\tvalid_1's rmse: 5.34987\n",
      "[3100]\ttraining's rmse: 5.2081\tvalid_1's rmse: 5.25103\n",
      "[3200]\ttraining's rmse: 5.117\tvalid_1's rmse: 5.16127\n",
      "[3300]\ttraining's rmse: 5.02857\tvalid_1's rmse: 5.07438\n",
      "[3400]\ttraining's rmse: 4.95153\tvalid_1's rmse: 4.99883\n",
      "[3500]\ttraining's rmse: 4.86851\tvalid_1's rmse: 4.91674\n",
      "[3600]\ttraining's rmse: 4.79753\tvalid_1's rmse: 4.84718\n",
      "[3700]\ttraining's rmse: 4.71645\tvalid_1's rmse: 4.76749\n",
      "[3800]\ttraining's rmse: 4.64606\tvalid_1's rmse: 4.69825\n",
      "[3900]\ttraining's rmse: 4.58516\tvalid_1's rmse: 4.63835\n",
      "[4000]\ttraining's rmse: 4.51917\tvalid_1's rmse: 4.5739\n",
      "[4100]\ttraining's rmse: 4.45854\tvalid_1's rmse: 4.51428\n",
      "[4200]\ttraining's rmse: 4.3995\tvalid_1's rmse: 4.45648\n",
      "[4300]\ttraining's rmse: 4.32878\tvalid_1's rmse: 4.38731\n",
      "[4400]\ttraining's rmse: 4.27505\tvalid_1's rmse: 4.33492\n",
      "[4500]\ttraining's rmse: 4.22194\tvalid_1's rmse: 4.28276\n",
      "[4600]\ttraining's rmse: 4.17284\tvalid_1's rmse: 4.23454\n",
      "[4700]\ttraining's rmse: 4.12803\tvalid_1's rmse: 4.19064\n",
      "[4800]\ttraining's rmse: 4.08275\tvalid_1's rmse: 4.14648\n",
      "[4900]\ttraining's rmse: 4.04318\tvalid_1's rmse: 4.10782\n",
      "[5000]\ttraining's rmse: 4.0049\tvalid_1's rmse: 4.07049\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's rmse: 4.0049\tvalid_1's rmse: 4.07049\n",
      "KFold: 4 ==> RMSE: 4.0729\n",
      "KFold: 5 Start\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 15.8773\tvalid_1's rmse: 15.9099\n",
      "[200]\ttraining's rmse: 13.8654\tvalid_1's rmse: 13.906\n",
      "[300]\ttraining's rmse: 12.9679\tvalid_1's rmse: 13.0121\n",
      "[400]\ttraining's rmse: 11.9289\tvalid_1's rmse: 11.9717\n",
      "[500]\ttraining's rmse: 10.9892\tvalid_1's rmse: 11.0307\n",
      "[600]\ttraining's rmse: 10.29\tvalid_1's rmse: 10.3321\n",
      "[700]\ttraining's rmse: 9.79882\tvalid_1's rmse: 9.84199\n",
      "[800]\ttraining's rmse: 9.37852\tvalid_1's rmse: 9.42338\n",
      "[900]\ttraining's rmse: 8.97585\tvalid_1's rmse: 9.02062\n",
      "[1000]\ttraining's rmse: 8.61093\tvalid_1's rmse: 8.65622\n",
      "[1100]\ttraining's rmse: 8.3082\tvalid_1's rmse: 8.35436\n",
      "[1200]\ttraining's rmse: 8.04522\tvalid_1's rmse: 8.09147\n",
      "[1300]\ttraining's rmse: 7.78795\tvalid_1's rmse: 7.8347\n",
      "[1400]\ttraining's rmse: 7.57776\tvalid_1's rmse: 7.62471\n",
      "[1500]\ttraining's rmse: 7.38466\tvalid_1's rmse: 7.43174\n",
      "[1600]\ttraining's rmse: 7.18121\tvalid_1's rmse: 7.22889\n",
      "[1700]\ttraining's rmse: 7.00195\tvalid_1's rmse: 7.04982\n",
      "[1800]\ttraining's rmse: 6.83561\tvalid_1's rmse: 6.88416\n",
      "[1900]\ttraining's rmse: 6.67225\tvalid_1's rmse: 6.72203\n",
      "[2000]\ttraining's rmse: 6.53317\tvalid_1's rmse: 6.58445\n",
      "[2100]\ttraining's rmse: 6.40011\tvalid_1's rmse: 6.45258\n",
      "[2200]\ttraining's rmse: 6.28044\tvalid_1's rmse: 6.33404\n",
      "[2300]\ttraining's rmse: 6.15217\tvalid_1's rmse: 6.2074\n",
      "[2400]\ttraining's rmse: 6.03813\tvalid_1's rmse: 6.09523\n",
      "[2500]\ttraining's rmse: 5.92211\tvalid_1's rmse: 5.98077\n",
      "[2600]\ttraining's rmse: 5.81291\tvalid_1's rmse: 5.87329\n",
      "[2700]\ttraining's rmse: 5.69825\tvalid_1's rmse: 5.76024\n",
      "[2800]\ttraining's rmse: 5.58814\tvalid_1's rmse: 5.65159\n",
      "[2900]\ttraining's rmse: 5.47501\tvalid_1's rmse: 5.5401\n",
      "[3000]\ttraining's rmse: 5.36225\tvalid_1's rmse: 5.42915\n",
      "[3100]\ttraining's rmse: 5.26645\tvalid_1's rmse: 5.33473\n",
      "[3200]\ttraining's rmse: 5.1851\tvalid_1's rmse: 5.25469\n",
      "[3300]\ttraining's rmse: 5.09334\tvalid_1's rmse: 5.16425\n",
      "[3400]\ttraining's rmse: 5.01021\tvalid_1's rmse: 5.0825\n",
      "[3500]\ttraining's rmse: 4.92776\tvalid_1's rmse: 5.00112\n",
      "[3600]\ttraining's rmse: 4.85049\tvalid_1's rmse: 4.92462\n",
      "[3700]\ttraining's rmse: 4.77814\tvalid_1's rmse: 4.85288\n",
      "[3800]\ttraining's rmse: 4.71138\tvalid_1's rmse: 4.78659\n",
      "[3900]\ttraining's rmse: 4.64912\tvalid_1's rmse: 4.72492\n",
      "[4000]\ttraining's rmse: 4.58622\tvalid_1's rmse: 4.66258\n",
      "[4100]\ttraining's rmse: 4.52418\tvalid_1's rmse: 4.60143\n",
      "[4200]\ttraining's rmse: 4.46748\tvalid_1's rmse: 4.54556\n",
      "[4300]\ttraining's rmse: 4.41017\tvalid_1's rmse: 4.48931\n",
      "[4400]\ttraining's rmse: 4.35643\tvalid_1's rmse: 4.43637\n",
      "[4500]\ttraining's rmse: 4.30258\tvalid_1's rmse: 4.38368\n",
      "[4600]\ttraining's rmse: 4.25266\tvalid_1's rmse: 4.3351\n",
      "[4700]\ttraining's rmse: 4.20671\tvalid_1's rmse: 4.29087\n",
      "[4800]\ttraining's rmse: 4.16095\tvalid_1's rmse: 4.24615\n",
      "[4900]\ttraining's rmse: 4.11263\tvalid_1's rmse: 4.19888\n",
      "[5000]\ttraining's rmse: 4.06941\tvalid_1's rmse: 4.15701\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's rmse: 4.06941\tvalid_1's rmse: 4.15701\n",
      "KFold: 5 ==> RMSE: 4.1444\n",
      "Average RMSE: 4.1112 ± 0.0263\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# データの準備\n",
    "X, y = train.iloc[:, 1:], train[\"Duration\"]\n",
    "X_test = test.iloc[:, 1:]\n",
    "y_test = test[\"Duration\"]\n",
    "\n",
    "# LightGBMのパラメータ設定\n",
    "params = {\n",
    "    'boosting_type': 'gbdt', # LightGBMでは 'gbdt' が通常の勾配ブースティングを表す\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.01,\n",
    "    'lambda_l2': 0.2,\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 64, # LightGBM特有のパラメータ、ツリーの葉の数\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'verbose': -1 # verboseの設定は -1, 0, 1 となります\n",
    "}\n",
    "\n",
    "# KFoldの設定\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rmse = []\n",
    "for i, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # LightGBM用データセットの作成\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "    \n",
    "    print(f\"KFold: {i+1} Start\")\n",
    "    \n",
    "    # モデル学習\n",
    "    model = lgb.train(params,\n",
    "                      lgb_train,\n",
    "                      num_boost_round=5000,\n",
    "                      valid_sets=[lgb_train, lgb_val],\n",
    "                      early_stopping_rounds=50,\n",
    "                      verbose_eval=100\n",
    "                     )\n",
    "    \n",
    "    # 推論\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "    score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse.append(score)\n",
    "    print(f\"KFold: {i+1} ==> RMSE: {score:.4f}\")\n",
    "    with open(f\"./models/baseline_lgbm/model_5000_{i+1}.pickle\", mode='wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "print(f\"Average RMSE: {np.mean(rmse):.4f} ± {np.std(rmse):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1269c5f-c4a9-4807-8af8-d5e4cb9c5bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold: 1 Start\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 18.8383\tvalid_1's rmse: 18.8267\n",
      "[100]\ttraining's rmse: 15.8812\tvalid_1's rmse: 15.8747\n",
      "[150]\ttraining's rmse: 14.5308\tvalid_1's rmse: 14.5283\n",
      "[200]\ttraining's rmse: 13.8641\tvalid_1's rmse: 13.864\n",
      "[250]\ttraining's rmse: 13.4032\tvalid_1's rmse: 13.404\n",
      "[300]\ttraining's rmse: 12.9578\tvalid_1's rmse: 12.96\n",
      "[350]\ttraining's rmse: 12.3919\tvalid_1's rmse: 12.3952\n",
      "[400]\ttraining's rmse: 11.8569\tvalid_1's rmse: 11.8616\n",
      "[450]\ttraining's rmse: 11.4214\tvalid_1's rmse: 11.4263\n",
      "[500]\ttraining's rmse: 10.9579\tvalid_1's rmse: 10.965\n",
      "[550]\ttraining's rmse: 10.5721\tvalid_1's rmse: 10.5815\n",
      "[600]\ttraining's rmse: 10.2697\tvalid_1's rmse: 10.2809\n",
      "[650]\ttraining's rmse: 10.0134\tvalid_1's rmse: 10.0252\n",
      "[700]\ttraining's rmse: 9.79374\tvalid_1's rmse: 9.80619\n",
      "[750]\ttraining's rmse: 9.58054\tvalid_1's rmse: 9.5938\n",
      "[800]\ttraining's rmse: 9.3625\tvalid_1's rmse: 9.3777\n",
      "[850]\ttraining's rmse: 9.15454\tvalid_1's rmse: 9.17085\n",
      "[900]\ttraining's rmse: 8.96426\tvalid_1's rmse: 8.98193\n",
      "[950]\ttraining's rmse: 8.78648\tvalid_1's rmse: 8.80554\n",
      "[1000]\ttraining's rmse: 8.60796\tvalid_1's rmse: 8.62824\n",
      "[1050]\ttraining's rmse: 8.45245\tvalid_1's rmse: 8.4737\n",
      "[1100]\ttraining's rmse: 8.29843\tvalid_1's rmse: 8.32077\n",
      "[1150]\ttraining's rmse: 8.15912\tvalid_1's rmse: 8.18233\n",
      "[1200]\ttraining's rmse: 8.02428\tvalid_1's rmse: 8.04829\n",
      "[1250]\ttraining's rmse: 7.89481\tvalid_1's rmse: 7.91961\n",
      "[1300]\ttraining's rmse: 7.77227\tvalid_1's rmse: 7.79786\n",
      "[1350]\ttraining's rmse: 7.6494\tvalid_1's rmse: 7.67613\n",
      "[1400]\ttraining's rmse: 7.53597\tvalid_1's rmse: 7.56373\n",
      "[1450]\ttraining's rmse: 7.42919\tvalid_1's rmse: 7.45844\n",
      "[1500]\ttraining's rmse: 7.33306\tvalid_1's rmse: 7.36364\n",
      "[1550]\ttraining's rmse: 7.24016\tvalid_1's rmse: 7.27214\n",
      "[1600]\ttraining's rmse: 7.14635\tvalid_1's rmse: 7.17982\n",
      "[1650]\ttraining's rmse: 7.05343\tvalid_1's rmse: 7.08808\n",
      "[1700]\ttraining's rmse: 6.96208\tvalid_1's rmse: 6.99794\n",
      "[1750]\ttraining's rmse: 6.8731\tvalid_1's rmse: 6.90965\n",
      "[1800]\ttraining's rmse: 6.79188\tvalid_1's rmse: 6.82961\n",
      "[1850]\ttraining's rmse: 6.70376\tvalid_1's rmse: 6.74215\n",
      "[1900]\ttraining's rmse: 6.62568\tvalid_1's rmse: 6.66473\n",
      "[1950]\ttraining's rmse: 6.55585\tvalid_1's rmse: 6.59544\n",
      "[2000]\ttraining's rmse: 6.47426\tvalid_1's rmse: 6.5141\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 6.47426\tvalid_1's rmse: 6.5141\n",
      "KFold: 1 ==> RMSE: 6.5242\n",
      "KFold: 2 Start\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 18.8378\tvalid_1's rmse: 18.8434\n",
      "[100]\ttraining's rmse: 15.886\tvalid_1's rmse: 15.8914\n",
      "[150]\ttraining's rmse: 14.5299\tvalid_1's rmse: 14.5363\n",
      "[200]\ttraining's rmse: 13.8587\tvalid_1's rmse: 13.867\n",
      "[250]\ttraining's rmse: 13.3999\tvalid_1's rmse: 13.4087\n",
      "[300]\ttraining's rmse: 12.9681\tvalid_1's rmse: 12.9779\n",
      "[350]\ttraining's rmse: 12.3891\tvalid_1's rmse: 12.4013\n",
      "[400]\ttraining's rmse: 11.9309\tvalid_1's rmse: 11.9454\n",
      "[450]\ttraining's rmse: 11.4825\tvalid_1's rmse: 11.4981\n",
      "[500]\ttraining's rmse: 11.0156\tvalid_1's rmse: 11.0318\n",
      "[550]\ttraining's rmse: 10.6379\tvalid_1's rmse: 10.6546\n",
      "[600]\ttraining's rmse: 10.325\tvalid_1's rmse: 10.3417\n",
      "[650]\ttraining's rmse: 10.0459\tvalid_1's rmse: 10.0629\n",
      "[700]\ttraining's rmse: 9.79321\tvalid_1's rmse: 9.81033\n",
      "[750]\ttraining's rmse: 9.56812\tvalid_1's rmse: 9.58562\n",
      "[800]\ttraining's rmse: 9.35105\tvalid_1's rmse: 9.3686\n",
      "[850]\ttraining's rmse: 9.17061\tvalid_1's rmse: 9.18818\n",
      "[900]\ttraining's rmse: 8.98787\tvalid_1's rmse: 9.00541\n",
      "[950]\ttraining's rmse: 8.80677\tvalid_1's rmse: 8.82411\n",
      "[1000]\ttraining's rmse: 8.63365\tvalid_1's rmse: 8.65115\n",
      "[1050]\ttraining's rmse: 8.48027\tvalid_1's rmse: 8.49793\n",
      "[1100]\ttraining's rmse: 8.32833\tvalid_1's rmse: 8.34644\n",
      "[1150]\ttraining's rmse: 8.18887\tvalid_1's rmse: 8.20737\n",
      "[1200]\ttraining's rmse: 8.04994\tvalid_1's rmse: 8.06815\n",
      "[1250]\ttraining's rmse: 7.92794\tvalid_1's rmse: 7.94639\n",
      "[1300]\ttraining's rmse: 7.81207\tvalid_1's rmse: 7.83105\n",
      "[1350]\ttraining's rmse: 7.69815\tvalid_1's rmse: 7.71745\n",
      "[1400]\ttraining's rmse: 7.5863\tvalid_1's rmse: 7.60588\n",
      "[1450]\ttraining's rmse: 7.48266\tvalid_1's rmse: 7.50239\n",
      "[1500]\ttraining's rmse: 7.37558\tvalid_1's rmse: 7.3956\n",
      "[1550]\ttraining's rmse: 7.27524\tvalid_1's rmse: 7.29517\n",
      "[1600]\ttraining's rmse: 7.17673\tvalid_1's rmse: 7.19657\n",
      "[1650]\ttraining's rmse: 7.08155\tvalid_1's rmse: 7.10119\n",
      "[1700]\ttraining's rmse: 6.99508\tvalid_1's rmse: 7.0145\n",
      "[1750]\ttraining's rmse: 6.91451\tvalid_1's rmse: 6.934\n",
      "[1800]\ttraining's rmse: 6.82635\tvalid_1's rmse: 6.84567\n",
      "[1850]\ttraining's rmse: 6.74092\tvalid_1's rmse: 6.76038\n",
      "[1900]\ttraining's rmse: 6.65507\tvalid_1's rmse: 6.67452\n",
      "[1950]\ttraining's rmse: 6.58167\tvalid_1's rmse: 6.60174\n",
      "[2000]\ttraining's rmse: 6.50736\tvalid_1's rmse: 6.52783\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 6.50736\tvalid_1's rmse: 6.52783\n",
      "KFold: 2 ==> RMSE: 6.5558\n",
      "KFold: 3 Start\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 18.8435\tvalid_1's rmse: 18.8069\n",
      "[100]\ttraining's rmse: 15.8913\tvalid_1's rmse: 15.854\n",
      "[150]\ttraining's rmse: 14.5432\tvalid_1's rmse: 14.5051\n",
      "[200]\ttraining's rmse: 13.8817\tvalid_1's rmse: 13.8423\n",
      "[250]\ttraining's rmse: 13.4161\tvalid_1's rmse: 13.3768\n",
      "[300]\ttraining's rmse: 12.9665\tvalid_1's rmse: 12.9277\n",
      "[350]\ttraining's rmse: 12.4014\tvalid_1's rmse: 12.3656\n",
      "[400]\ttraining's rmse: 11.9263\tvalid_1's rmse: 11.8934\n",
      "[450]\ttraining's rmse: 11.4653\tvalid_1's rmse: 11.4367\n",
      "[500]\ttraining's rmse: 11.014\tvalid_1's rmse: 10.9901\n",
      "[550]\ttraining's rmse: 10.6331\tvalid_1's rmse: 10.6122\n",
      "[600]\ttraining's rmse: 10.3255\tvalid_1's rmse: 10.3077\n",
      "[650]\ttraining's rmse: 10.0575\tvalid_1's rmse: 10.0414\n",
      "[700]\ttraining's rmse: 9.80764\tvalid_1's rmse: 9.7924\n",
      "[750]\ttraining's rmse: 9.58168\tvalid_1's rmse: 9.56771\n",
      "[800]\ttraining's rmse: 9.36543\tvalid_1's rmse: 9.35253\n",
      "[850]\ttraining's rmse: 9.17109\tvalid_1's rmse: 9.15985\n",
      "[900]\ttraining's rmse: 8.97976\tvalid_1's rmse: 8.97068\n",
      "[950]\ttraining's rmse: 8.79396\tvalid_1's rmse: 8.7863\n",
      "[1000]\ttraining's rmse: 8.60321\tvalid_1's rmse: 8.59746\n",
      "[1050]\ttraining's rmse: 8.44388\tvalid_1's rmse: 8.44008\n",
      "[1100]\ttraining's rmse: 8.30395\tvalid_1's rmse: 8.30181\n",
      "[1150]\ttraining's rmse: 8.15688\tvalid_1's rmse: 8.15642\n",
      "[1200]\ttraining's rmse: 8.02853\tvalid_1's rmse: 8.02905\n",
      "[1250]\ttraining's rmse: 7.90776\tvalid_1's rmse: 7.90904\n",
      "[1300]\ttraining's rmse: 7.78149\tvalid_1's rmse: 7.78399\n",
      "[1350]\ttraining's rmse: 7.67388\tvalid_1's rmse: 7.67743\n",
      "[1400]\ttraining's rmse: 7.5643\tvalid_1's rmse: 7.56877\n",
      "[1450]\ttraining's rmse: 7.46396\tvalid_1's rmse: 7.46969\n",
      "[1500]\ttraining's rmse: 7.35744\tvalid_1's rmse: 7.3647\n",
      "[1550]\ttraining's rmse: 7.25331\tvalid_1's rmse: 7.26221\n",
      "[1600]\ttraining's rmse: 7.1536\tvalid_1's rmse: 7.16398\n",
      "[1650]\ttraining's rmse: 7.05466\tvalid_1's rmse: 7.06611\n",
      "[1700]\ttraining's rmse: 6.95695\tvalid_1's rmse: 6.96971\n",
      "[1750]\ttraining's rmse: 6.87046\tvalid_1's rmse: 6.88397\n",
      "[1800]\ttraining's rmse: 6.78737\tvalid_1's rmse: 6.8016\n",
      "[1850]\ttraining's rmse: 6.69986\tvalid_1's rmse: 6.71488\n",
      "[1900]\ttraining's rmse: 6.62162\tvalid_1's rmse: 6.63688\n",
      "[1950]\ttraining's rmse: 6.54767\tvalid_1's rmse: 6.56378\n",
      "[2000]\ttraining's rmse: 6.47072\tvalid_1's rmse: 6.48716\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 6.47072\tvalid_1's rmse: 6.48716\n",
      "KFold: 3 ==> RMSE: 6.5183\n",
      "KFold: 4 Start\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 18.8341\tvalid_1's rmse: 18.8547\n",
      "[100]\ttraining's rmse: 15.8791\tvalid_1's rmse: 15.8987\n",
      "[150]\ttraining's rmse: 14.5308\tvalid_1's rmse: 14.5494\n",
      "[200]\ttraining's rmse: 13.8584\tvalid_1's rmse: 13.8773\n",
      "[250]\ttraining's rmse: 13.4028\tvalid_1's rmse: 13.4224\n",
      "[300]\ttraining's rmse: 12.9597\tvalid_1's rmse: 12.9787\n",
      "[350]\ttraining's rmse: 12.3952\tvalid_1's rmse: 12.4144\n",
      "[400]\ttraining's rmse: 11.9024\tvalid_1's rmse: 11.921\n",
      "[450]\ttraining's rmse: 11.4324\tvalid_1's rmse: 11.4511\n",
      "[500]\ttraining's rmse: 10.9781\tvalid_1's rmse: 10.997\n",
      "[550]\ttraining's rmse: 10.5956\tvalid_1's rmse: 10.6151\n",
      "[600]\ttraining's rmse: 10.2833\tvalid_1's rmse: 10.3035\n",
      "[650]\ttraining's rmse: 10.0168\tvalid_1's rmse: 10.0373\n",
      "[700]\ttraining's rmse: 9.77878\tvalid_1's rmse: 9.7994\n",
      "[750]\ttraining's rmse: 9.56139\tvalid_1's rmse: 9.58319\n",
      "[800]\ttraining's rmse: 9.35965\tvalid_1's rmse: 9.38263\n",
      "[850]\ttraining's rmse: 9.17208\tvalid_1's rmse: 9.19597\n",
      "[900]\ttraining's rmse: 9.00439\tvalid_1's rmse: 9.0285\n",
      "[950]\ttraining's rmse: 8.82541\tvalid_1's rmse: 8.84988\n",
      "[1000]\ttraining's rmse: 8.66549\tvalid_1's rmse: 8.69054\n",
      "[1050]\ttraining's rmse: 8.49642\tvalid_1's rmse: 8.5218\n",
      "[1100]\ttraining's rmse: 8.33547\tvalid_1's rmse: 8.36099\n",
      "[1150]\ttraining's rmse: 8.1822\tvalid_1's rmse: 8.2079\n",
      "[1200]\ttraining's rmse: 8.05853\tvalid_1's rmse: 8.08436\n",
      "[1250]\ttraining's rmse: 7.94405\tvalid_1's rmse: 7.97011\n",
      "[1300]\ttraining's rmse: 7.82557\tvalid_1's rmse: 7.85221\n",
      "[1350]\ttraining's rmse: 7.71962\tvalid_1's rmse: 7.74679\n",
      "[1400]\ttraining's rmse: 7.60889\tvalid_1's rmse: 7.63673\n",
      "[1450]\ttraining's rmse: 7.51414\tvalid_1's rmse: 7.5426\n",
      "[1500]\ttraining's rmse: 7.40491\tvalid_1's rmse: 7.43347\n",
      "[1550]\ttraining's rmse: 7.29638\tvalid_1's rmse: 7.32539\n",
      "[1600]\ttraining's rmse: 7.19802\tvalid_1's rmse: 7.22742\n",
      "[1650]\ttraining's rmse: 7.1087\tvalid_1's rmse: 7.13826\n",
      "[1700]\ttraining's rmse: 7.02081\tvalid_1's rmse: 7.05095\n",
      "[1750]\ttraining's rmse: 6.9249\tvalid_1's rmse: 6.95542\n",
      "[1800]\ttraining's rmse: 6.83345\tvalid_1's rmse: 6.86432\n",
      "[1850]\ttraining's rmse: 6.74407\tvalid_1's rmse: 6.77551\n",
      "[1900]\ttraining's rmse: 6.6683\tvalid_1's rmse: 6.70017\n",
      "[1950]\ttraining's rmse: 6.58252\tvalid_1's rmse: 6.6147\n",
      "[2000]\ttraining's rmse: 6.50452\tvalid_1's rmse: 6.53749\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 6.50452\tvalid_1's rmse: 6.53749\n",
      "KFold: 4 ==> RMSE: 6.5523\n",
      "KFold: 5 Start\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 18.8319\tvalid_1's rmse: 18.86\n",
      "[100]\ttraining's rmse: 15.8776\tvalid_1's rmse: 15.9102\n",
      "[150]\ttraining's rmse: 14.5299\tvalid_1's rmse: 14.567\n",
      "[200]\ttraining's rmse: 13.8617\tvalid_1's rmse: 13.9024\n",
      "[250]\ttraining's rmse: 13.3884\tvalid_1's rmse: 13.4308\n",
      "[300]\ttraining's rmse: 12.957\tvalid_1's rmse: 13.0008\n",
      "[350]\ttraining's rmse: 12.4022\tvalid_1's rmse: 12.4447\n",
      "[400]\ttraining's rmse: 11.9382\tvalid_1's rmse: 11.9807\n",
      "[450]\ttraining's rmse: 11.4535\tvalid_1's rmse: 11.4955\n",
      "[500]\ttraining's rmse: 10.981\tvalid_1's rmse: 11.022\n",
      "[550]\ttraining's rmse: 10.6061\tvalid_1's rmse: 10.6471\n",
      "[600]\ttraining's rmse: 10.2931\tvalid_1's rmse: 10.3343\n",
      "[650]\ttraining's rmse: 10.0223\tvalid_1's rmse: 10.0644\n",
      "[700]\ttraining's rmse: 9.79427\tvalid_1's rmse: 9.8369\n",
      "[750]\ttraining's rmse: 9.56874\tvalid_1's rmse: 9.61176\n",
      "[800]\ttraining's rmse: 9.37616\tvalid_1's rmse: 9.4199\n",
      "[850]\ttraining's rmse: 9.17599\tvalid_1's rmse: 9.22066\n",
      "[900]\ttraining's rmse: 8.98434\tvalid_1's rmse: 9.02912\n",
      "[950]\ttraining's rmse: 8.78207\tvalid_1's rmse: 8.82695\n",
      "[1000]\ttraining's rmse: 8.60399\tvalid_1's rmse: 8.64873\n",
      "[1050]\ttraining's rmse: 8.44922\tvalid_1's rmse: 8.49438\n",
      "[1100]\ttraining's rmse: 8.29773\tvalid_1's rmse: 8.34292\n",
      "[1150]\ttraining's rmse: 8.16531\tvalid_1's rmse: 8.21062\n",
      "[1200]\ttraining's rmse: 8.04923\tvalid_1's rmse: 8.09491\n",
      "[1250]\ttraining's rmse: 7.93117\tvalid_1's rmse: 7.97707\n",
      "[1300]\ttraining's rmse: 7.8195\tvalid_1's rmse: 7.86527\n",
      "[1350]\ttraining's rmse: 7.71335\tvalid_1's rmse: 7.75917\n",
      "[1400]\ttraining's rmse: 7.60269\tvalid_1's rmse: 7.64845\n",
      "[1450]\ttraining's rmse: 7.49233\tvalid_1's rmse: 7.53826\n",
      "[1500]\ttraining's rmse: 7.39215\tvalid_1's rmse: 7.43881\n",
      "[1550]\ttraining's rmse: 7.28798\tvalid_1's rmse: 7.33498\n",
      "[1600]\ttraining's rmse: 7.19369\tvalid_1's rmse: 7.2414\n",
      "[1650]\ttraining's rmse: 7.09946\tvalid_1's rmse: 7.14755\n",
      "[1700]\ttraining's rmse: 7.0073\tvalid_1's rmse: 7.05586\n",
      "[1750]\ttraining's rmse: 6.92009\tvalid_1's rmse: 6.9692\n",
      "[1800]\ttraining's rmse: 6.84471\tvalid_1's rmse: 6.89416\n",
      "[1850]\ttraining's rmse: 6.75812\tvalid_1's rmse: 6.80854\n",
      "[1900]\ttraining's rmse: 6.67644\tvalid_1's rmse: 6.72776\n",
      "[1950]\ttraining's rmse: 6.60114\tvalid_1's rmse: 6.65326\n",
      "[2000]\ttraining's rmse: 6.52907\tvalid_1's rmse: 6.58191\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 6.52907\tvalid_1's rmse: 6.58191\n",
      "KFold: 5 ==> RMSE: 6.5827\n",
      "Average RMSE: 6.5467 ± 0.0233\n"
     ]
    }
   ],
   "source": [
    "# データの準備\n",
    "X, y = train.iloc[:, 1:], train[\"Duration\"]\n",
    "X_test = test.iloc[:, 1:]\n",
    "y_test = test[\"Duration\"]\n",
    "\n",
    "# LightGBMのパラメータ設定\n",
    "params = {\n",
    "    'boosting_type': 'gbdt', # LightGBMでは 'gbdt' が通常の勾配ブースティングを表す\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.01,\n",
    "    'lambda_l2': 0.1,\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 64, # LightGBM特有のパラメータ、ツリーの葉の数\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'verbose': -1 # verboseの設定は -1, 0, 1 となります\n",
    "}\n",
    "\n",
    "# KFoldの設定\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rmse = []\n",
    "for i, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # LightGBM用データセットの作成\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "    \n",
    "    print(f\"KFold: {i+1} Start\")\n",
    "    \n",
    "    # モデル学習\n",
    "    model = lgb.train(params,\n",
    "                      lgb_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=[lgb_train, lgb_val],\n",
    "                      early_stopping_rounds=50,\n",
    "                      verbose_eval=50\n",
    "                     )\n",
    "    \n",
    "    # 推論\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "    score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse.append(score)\n",
    "    print(f\"KFold: {i+1} ==> RMSE: {score:.4f}\")\n",
    "    with open(f\"./models/baseline_lgbm/model_2000_{i+1}.pickle\", mode='wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "print(f\"Average RMSE: {np.mean(rmse):.4f} ± {np.std(rmse):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4ded8b-d793-4233-bfef-3d83c4db459c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
